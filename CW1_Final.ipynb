{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CW1_t.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "UmJn1lwBcDgl"
      ]
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "zmZ40vrjF-D8"
      },
      "source": [
        "# Preprocess\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "8_9Hpwt8BQDr",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import os\n",
        "import io\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
        "import numpy as np\n",
        "np.seterr(divide='ignore', invalid='ignore')\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a_R3IAb5_cSI",
        "colab_type": "code",
        "outputId": "f44bf3e0-aeeb-4871-9420-8c5fedab6a0c",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 77
        }
      },
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-9fe9623b-f49a-4d18-990b-b5612c6311a9\" name=\"files[]\" multiple disabled />\n",
              "     <output id=\"result-9fe9623b-f49a-4d18-990b-b5612c6311a9\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving Loan_data_part_I.csv to Loan_data_part_I.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l9HC-Lst_ksN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_loan = pd.read_csv(io.StringIO(uploaded['Loan_data_part_I.csv'].decode('utf-8')))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "YZHfr7AdSJcE",
        "outputId": "649d6e34-eed3-4211-bc08-e84f7c1f046c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 215
        }
      },
      "source": [
        "df_loan = pd.read_csv(\"/Users/wuyating/Desktop/Assignment/Loan_data_part_I.csv\")\n",
        "df_loan.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>loan_status</th>\n",
              "      <th>loan_amnt</th>\n",
              "      <th>term</th>\n",
              "      <th>int_rate</th>\n",
              "      <th>sub_grade</th>\n",
              "      <th>installment</th>\n",
              "      <th>annual_inc</th>\n",
              "      <th>emp_length</th>\n",
              "      <th>dti</th>\n",
              "      <th>fico_range_high</th>\n",
              "      <th>...</th>\n",
              "      <th>pub_rec</th>\n",
              "      <th>pub_rec_bankruptcies</th>\n",
              "      <th>revol_bal</th>\n",
              "      <th>revol_util</th>\n",
              "      <th>tax_liens</th>\n",
              "      <th>tot_cur_bal</th>\n",
              "      <th>tot_hi_cred_lim</th>\n",
              "      <th>total_acc</th>\n",
              "      <th>total_bal_ex_mort</th>\n",
              "      <th>total_bc_limit</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Current</td>\n",
              "      <td>4800.0</td>\n",
              "      <td>36.0</td>\n",
              "      <td>19.20</td>\n",
              "      <td>17</td>\n",
              "      <td>176.44</td>\n",
              "      <td>36000.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>18.97</td>\n",
              "      <td>664.0</td>\n",
              "      <td>...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>3967.0</td>\n",
              "      <td>94.5</td>\n",
              "      <td>0.0</td>\n",
              "      <td>16019.0</td>\n",
              "      <td>25093.0</td>\n",
              "      <td>13.0</td>\n",
              "      <td>16019.0</td>\n",
              "      <td>4200.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Current</td>\n",
              "      <td>21000.0</td>\n",
              "      <td>36.0</td>\n",
              "      <td>13.11</td>\n",
              "      <td>8</td>\n",
              "      <td>708.69</td>\n",
              "      <td>90000.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>16.75</td>\n",
              "      <td>699.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>35234.0</td>\n",
              "      <td>90.3</td>\n",
              "      <td>0.0</td>\n",
              "      <td>38768.0</td>\n",
              "      <td>54907.0</td>\n",
              "      <td>24.0</td>\n",
              "      <td>38768.0</td>\n",
              "      <td>35900.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Current</td>\n",
              "      <td>10750.0</td>\n",
              "      <td>36.0</td>\n",
              "      <td>15.80</td>\n",
              "      <td>12</td>\n",
              "      <td>376.88</td>\n",
              "      <td>47000.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>14.09</td>\n",
              "      <td>679.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>8247.0</td>\n",
              "      <td>56.9</td>\n",
              "      <td>0.0</td>\n",
              "      <td>14233.0</td>\n",
              "      <td>21285.0</td>\n",
              "      <td>16.0</td>\n",
              "      <td>14233.0</td>\n",
              "      <td>6700.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Current</td>\n",
              "      <td>10200.0</td>\n",
              "      <td>60.0</td>\n",
              "      <td>15.61</td>\n",
              "      <td>13</td>\n",
              "      <td>245.94</td>\n",
              "      <td>60000.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>21.30</td>\n",
              "      <td>684.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>12834.0</td>\n",
              "      <td>70.1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>145664.0</td>\n",
              "      <td>187118.0</td>\n",
              "      <td>32.0</td>\n",
              "      <td>21069.0</td>\n",
              "      <td>7800.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Current</td>\n",
              "      <td>9500.0</td>\n",
              "      <td>36.0</td>\n",
              "      <td>13.11</td>\n",
              "      <td>8</td>\n",
              "      <td>320.60</td>\n",
              "      <td>106000.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>9.76</td>\n",
              "      <td>694.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>18345.0</td>\n",
              "      <td>31.7</td>\n",
              "      <td>0.0</td>\n",
              "      <td>18345.0</td>\n",
              "      <td>57800.0</td>\n",
              "      <td>54.0</td>\n",
              "      <td>18345.0</td>\n",
              "      <td>31200.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows Ã— 36 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "  loan_status  loan_amnt  term  int_rate  sub_grade  installment  annual_inc  \\\n",
              "0     Current     4800.0  36.0     19.20         17       176.44     36000.0   \n",
              "1     Current    21000.0  36.0     13.11          8       708.69     90000.0   \n",
              "2     Current    10750.0  36.0     15.80         12       376.88     47000.0   \n",
              "3     Current    10200.0  60.0     15.61         13       245.94     60000.0   \n",
              "4     Current     9500.0  36.0     13.11          8       320.60    106000.0   \n",
              "\n",
              "   emp_length    dti  fico_range_high  ...  pub_rec  pub_rec_bankruptcies  \\\n",
              "0        10.0  18.97            664.0  ...      1.0                   1.0   \n",
              "1         6.0  16.75            699.0  ...      0.0                   0.0   \n",
              "2        10.0  14.09            679.0  ...      0.0                   0.0   \n",
              "3         6.0  21.30            684.0  ...      0.0                   0.0   \n",
              "4        10.0   9.76            694.0  ...      0.0                   0.0   \n",
              "\n",
              "   revol_bal  revol_util  tax_liens  tot_cur_bal  tot_hi_cred_lim  total_acc  \\\n",
              "0     3967.0        94.5        0.0      16019.0          25093.0       13.0   \n",
              "1    35234.0        90.3        0.0      38768.0          54907.0       24.0   \n",
              "2     8247.0        56.9        0.0      14233.0          21285.0       16.0   \n",
              "3    12834.0        70.1        0.0     145664.0         187118.0       32.0   \n",
              "4    18345.0        31.7        0.0      18345.0          57800.0       54.0   \n",
              "\n",
              "   total_bal_ex_mort  total_bc_limit  \n",
              "0            16019.0          4200.0  \n",
              "1            38768.0         35900.0  \n",
              "2            14233.0          6700.0  \n",
              "3            21069.0          7800.0  \n",
              "4            18345.0         31200.0  \n",
              "\n",
              "[5 rows x 36 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6WPk3RTa-UJP",
        "colab_type": "code",
        "outputId": "7d895299-dd46-4bc1-a913-49f69cb80f19",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 638
        }
      },
      "source": [
        "df_loan[\"home_ownership\"]=df_loan[\"home_ownership\"].astype(\"category\")\n",
        "df_loan[\"purpose\"]=df_loan[\"purpose\"].astype(\"category\")\n",
        "df_loan[\"sub_grade\"]=df_loan[\"sub_grade\"].astype(\"category\")\n",
        "df_loan[\"verification_status\"]=df_loan[\"verification_status\"].astype(\"category\")\n",
        "df_loan[\"loan_status\"]=np.where(df_loan[\"loan_status\"] == 'Fail',\"1\",\"0\")\n",
        "df_loan[\"loan_status\"]=df_loan[\"loan_status\"].astype(\"category\")\n",
        "df_loan.dtypes"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "loan_status              category\n",
              "loan_amnt                 float64\n",
              "term                      float64\n",
              "int_rate                  float64\n",
              "sub_grade                category\n",
              "installment               float64\n",
              "annual_inc                float64\n",
              "emp_length                float64\n",
              "dti                       float64\n",
              "fico_range_high           float64\n",
              "verification_status      category\n",
              "purpose                  category\n",
              "home_ownership           category\n",
              "avg_cur_bal               float64\n",
              "delinq_2yrs               float64\n",
              "delinq_amnt               float64\n",
              "earliest_cr_line          float64\n",
              "inq_last_6mths            float64\n",
              "num_accts_ever_120_pd     float64\n",
              "num_actv_bc_tl            float64\n",
              "num_bc_tl                 float64\n",
              "num_il_tl                 float64\n",
              "num_op_rev_tl             float64\n",
              "num_rev_accts             float64\n",
              "num_tl_90g_dpd_24m        float64\n",
              "percent_bc_gt_75          float64\n",
              "pub_rec                   float64\n",
              "pub_rec_bankruptcies      float64\n",
              "revol_bal                 float64\n",
              "revol_util                float64\n",
              "tax_liens                 float64\n",
              "tot_cur_bal               float64\n",
              "tot_hi_cred_lim           float64\n",
              "total_acc                 float64\n",
              "total_bal_ex_mort         float64\n",
              "total_bc_limit            float64\n",
              "dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "vw1xqe5szPQY"
      },
      "source": [
        "\n",
        "#Q1\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "AD1Ub0Tc-4go"
      },
      "source": [
        "\n",
        "1.(10 points) Apply three different machine-learning techniques: linear discriminant analysis (LDA), Random Forest classification (with 100 trees), and 50-NN to the FULL-MODEL and entire dataset in order to predict loan default. To obtain a measure of how good each technique is at using these attributes to predict default, compute the confusion matrix of each measure, using the method of 10-fold cross validation. Complete the following tables with the confusion matrices of each method for prediction (note: please normalize all confusion matrices by dividing each cell by its column-total, such that it reacts the share of predicted observations that fall in that outcome category (Current or Default) and both columns sum up to 1)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "pFJFP1puAGSP",
        "colab": {}
      },
      "source": [
        "y=df_loan[\"loan_status\"]\n",
        "X=df_loan.iloc[:,df_loan.columns!=\"loan_status\"]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "m7XaDSIvAVRH",
        "colab": {}
      },
      "source": [
        "# Applying k-Fold Cross Validation\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from imblearn.under_sampling import RandomUnderSampler"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "VLp2UZ001T0G",
        "colab": {}
      },
      "source": [
        "kf = KFold(n_splits = 10, shuffle = False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "D6vkJ1rbAXvK",
        "colab": {}
      },
      "source": [
        "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "#from sklearn import metrics\n",
        "# Classifier\n",
        "model_dict = {\n",
        "    'LDA':LinearDiscriminantAnalysis()\n",
        "    ,'Random Forest':RandomForestClassifier(n_estimators=100)\n",
        "    ,'KNN':KNeighborsClassifier(n_neighbors=50)\n",
        "}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "yk0OcOsbAZVX",
        "colab": {}
      },
      "source": [
        "def main(X, i = 0):  \n",
        "  for model in model_dict:    \n",
        "    # Initialize the array to zero which will store the confusion matrix\n",
        "    array = [[0,0],[0,0]]\n",
        "    \n",
        "    # For each train-test split: train, predict and compute the confusion matrix\n",
        "    for train_index, test_index in kf.split(X):\n",
        "      X_train_raw, X_test_raw = X.iloc[train_index], X.iloc[test_index]\n",
        "      y_train, y_test = y[train_index], y[test_index]\n",
        "\n",
        "      # Whether balancing data\n",
        "      if i == 1:\n",
        "        X_train_raw, y_train = RandomUnderSampler(random_state=0).fit_sample(X_train_raw,y_train)\n",
        "      else:\n",
        "        pass\n",
        "        \n",
        "      # Feature Scaling\n",
        "      stdsc = StandardScaler()\n",
        "      X_train = stdsc.fit_transform(X_train_raw)\n",
        "      X_test = stdsc.transform(X_test_raw)\n",
        "    \n",
        "      # Train the model\n",
        "      model_train = model_dict[model].fit(X_train,y_train)\n",
        "\n",
        "      # Calculate the confusion matrix\n",
        "      cm = confusion_matrix(y_test, model_train.predict(X_test))\n",
        "      cm = cm.T\n",
        "      # Add the score to the previous confusion matrix of previous model\n",
        "      array = array + cm\n",
        "\n",
        "      # Nornalised cfmat\n",
        "      Nor_cfmat = array/ array.astype(np.float).sum(axis=0)\n",
        "      df = pd.DataFrame(Nor_cfmat, index = ['Predicted Not Default', 'Predicted Default'], columns = ['Actual Not Default', 'Actual Default'])\n",
        "        \n",
        "    print(model,'\\tBalanced data' if i == 1  else '\\tImbalanced data')\n",
        "    print(df)\n",
        "    print(\"\\n\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "WP06HxFkAcmX",
        "outputId": "b4f6f3b9-40a2-492d-875a-ac36cb9823cb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 319
        }
      },
      "source": [
        "main(X)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "LDA \tImbalanced data\n",
            "                       Actual Not Default  Actual Default\n",
            "Predicted Not Default            0.933251        0.926703\n",
            "Predicted Default                0.066749        0.073297\n",
            "\n",
            "\n",
            "Random Forest \tImbalanced data\n",
            "                       Actual Not Default  Actual Default\n",
            "Predicted Not Default            0.936794        0.965866\n",
            "Predicted Default                0.063206        0.034134\n",
            "\n",
            "\n",
            "KNN \tImbalanced data\n",
            "                       Actual Not Default  Actual Default\n",
            "Predicted Not Default            0.950746        0.981917\n",
            "Predicted Default                0.049254        0.018083\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "TJMy7iLIzWQ_"
      },
      "source": [
        "# Q2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "KczoTBCkAjbF"
      },
      "source": [
        "2a.Undersample the number \"Current\" to have 50% \"Fail\" and 50% \n",
        "\"Current\" in your training set. Rerun the three previous machine-learning techniques and compute the confusion matrices.\n",
        "Are the predictions better? Explain\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "zmgtLTe-Ad9H",
        "outputId": "87fc593c-a6fc-4e55-c745-f87e7ef69914",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 319
        }
      },
      "source": [
        "main(X,1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "LDA \tBalanced data\n",
            "                       Actual Not Default  Actual Default\n",
            "Predicted Not Default            0.625655        0.348656\n",
            "Predicted Default                0.374345        0.651344\n",
            "\n",
            "\n",
            "Random Forest \tBalanced data\n",
            "                       Actual Not Default  Actual Default\n",
            "Predicted Not Default            0.627943        0.364606\n",
            "Predicted Default                0.372057        0.635394\n",
            "\n",
            "\n",
            "KNN \tBalanced data\n",
            "                       Actual Not Default  Actual Default\n",
            "Predicted Not Default            0.636174         0.38086\n",
            "Predicted Default                0.363826         0.61914\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "RTjVyWkIpwdr"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "wwXGqKtIZ1ls"
      },
      "source": [
        "2b.In the previous questions, we gave you the hyperparameter for the k-nearest neighbors\n",
        "model (with k=50). This parameter should be found through cross-validation. Write a pseudo-code\n",
        "showing how you would nd the optimal value for this hyperparameter.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "k1wuIE5XZ4Wb",
        "colab": {}
      },
      "source": [
        "# Initialize an cross validation error list CV\n",
        "# For each K = 2, 3, 4, ... , 50\n",
        "#   Split 70% dataset into 10 folds\n",
        "#   For j = 1, 2, ... , 10\n",
        "#     Use [j] fold as test set and the remaining folds as training set\n",
        "#     Fit model\n",
        "#     Use fitted model to validate results in test set and record the error\n",
        "#   Calculate mean of the 10 errors and record in CV, marked as K's error.\n",
        "# Select K with lowest error as hyperparameter0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "r-SdCDFkzfFD"
      },
      "source": [
        "#Q3\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "yWp8SH6rgRos"
      },
      "source": [
        "3a.Which loan attributes do you believe are the most informative? Please use your knowledge\n",
        "and intuition to choose 10 of the attributes, and provide a brief justi cation for why you chose these\n",
        "attributes. Let's call this the REDUCED-MODEL"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "V4W6AabW7Yu_"
      },
      "source": [
        "In our prediction model, it is important to grading clusters of borrowers instead of grading individuals based on their credit behaviors. However, if we manipulate some features incorrectly, it will overfitting or underfitting our analysis. First, some column discloses information after the loan has already been funded. Second, some column does not alter the borrower's ability to pay back the loan. Third, some column contains redundant information. Therefore, after analyzing each column in DataDictionary, we can drop these columns in which content incorrect features, and choose 10 column to analysis.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "5Qk07l6sIefk"
      },
      "source": [
        "1.int_rate 2.loan_amnt 3.installment 4.emp_length 5.home_ownership 6.annual_inc 7.num_accts_ever_120_pd 8.avg_cur_bal 9.term 10.revol_util "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Hgfi8cZ57ZvO"
      },
      "source": [
        "3b.Apply the set of di erent machine-learning techniques with one change { logistic regression instead of LDA (i.e., logistic regression, Random Forest classi cation, and 50-NN) to the REDUCED-MODEL dataset in order to predict loan default. Again, to obtain a measure of how good these techniques are at predicting default, compute their confusion matrices using 10-fold cross validation.\n",
        "Please undersample again using the number \"Current\" to have 50% \"Fail\" and 50% \"Current\" in your\n",
        "subsample.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "PHupJJUc9Btn",
        "outputId": "3d82b70b-e3e8-4107-aa8b-a14f41766389",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        }
      },
      "source": [
        "used_cols=['int_rate','loan_amnt','installment','emp_length','home_ownership','annual_inc','num_accts_ever_120_pd','avg_cur_bal','term','revol_util']\n",
        "reduced_data = df_loan[used_cols]\n",
        "reduced_data.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>int_rate</th>\n",
              "      <th>loan_amnt</th>\n",
              "      <th>installment</th>\n",
              "      <th>emp_length</th>\n",
              "      <th>home_ownership</th>\n",
              "      <th>annual_inc</th>\n",
              "      <th>num_accts_ever_120_pd</th>\n",
              "      <th>avg_cur_bal</th>\n",
              "      <th>term</th>\n",
              "      <th>revol_util</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>19.20</td>\n",
              "      <td>4800.0</td>\n",
              "      <td>176.44</td>\n",
              "      <td>10.0</td>\n",
              "      <td>1</td>\n",
              "      <td>36000.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3204.0</td>\n",
              "      <td>36.0</td>\n",
              "      <td>94.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>13.11</td>\n",
              "      <td>21000.0</td>\n",
              "      <td>708.69</td>\n",
              "      <td>6.0</td>\n",
              "      <td>5</td>\n",
              "      <td>90000.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>4846.0</td>\n",
              "      <td>36.0</td>\n",
              "      <td>90.3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>15.80</td>\n",
              "      <td>10750.0</td>\n",
              "      <td>376.88</td>\n",
              "      <td>10.0</td>\n",
              "      <td>4</td>\n",
              "      <td>47000.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1423.0</td>\n",
              "      <td>36.0</td>\n",
              "      <td>56.9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>15.61</td>\n",
              "      <td>10200.0</td>\n",
              "      <td>245.94</td>\n",
              "      <td>6.0</td>\n",
              "      <td>1</td>\n",
              "      <td>60000.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>12139.0</td>\n",
              "      <td>60.0</td>\n",
              "      <td>70.1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>13.11</td>\n",
              "      <td>9500.0</td>\n",
              "      <td>320.60</td>\n",
              "      <td>10.0</td>\n",
              "      <td>1</td>\n",
              "      <td>106000.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>966.0</td>\n",
              "      <td>36.0</td>\n",
              "      <td>31.7</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   int_rate  loan_amnt  installment  ...  avg_cur_bal  term  revol_util\n",
              "0     19.20     4800.0       176.44  ...       3204.0  36.0        94.5\n",
              "1     13.11    21000.0       708.69  ...       4846.0  36.0        90.3\n",
              "2     15.80    10750.0       376.88  ...       1423.0  36.0        56.9\n",
              "3     15.61    10200.0       245.94  ...      12139.0  60.0        70.1\n",
              "4     13.11     9500.0       320.60  ...        966.0  36.0        31.7\n",
              "\n",
              "[5 rows x 10 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "iac08l-mbAE6",
        "colab": {}
      },
      "source": [
        "from sklearn.linear_model import SGDClassifier\n",
        "from sklearn.linear_model import LogisticRegression"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "2JY2XKDjbA6I",
        "colab": {}
      },
      "source": [
        "# Classifier\n",
        "model_dict2 = {\n",
        "    'LogisticReg':LogisticRegression()\n",
        "    ,'Random Forest':RandomForestClassifier(n_estimators=100)\n",
        "    ,'KNN':KNeighborsClassifier(n_neighbors=50)\n",
        "}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ebhxztILbBFC",
        "colab": {}
      },
      "source": [
        "def reduce(reduced_data, i = 0):  \n",
        "  for model in model_dict2:    \n",
        "    # Initialize the array to zero which will store the confusion matrix\n",
        "    array = [[0,0],[0,0]]\n",
        "    \n",
        "    # For each train-test split: train, predict and compute the confusion matrix\n",
        "    for train_index, test_index in kf.split(reduced_data):\n",
        "      X_train_raw, X_test_raw = reduced_data.iloc[train_index], reduced_data.iloc[test_index]\n",
        "      y_train, y_test = y[train_index], y[test_index]\n",
        "\n",
        "      # Whether balancing data\n",
        "      if i == 1:\n",
        "        X_train_raw, y_train = RandomUnderSampler(random_state=0).fit_sample(X_train_raw,y_train)\n",
        "      else:\n",
        "        pass\n",
        "        \n",
        "      # Feature Scaling\n",
        "      stdsc = StandardScaler()\n",
        "      X_train = stdsc.fit_transform(X_train_raw)\n",
        "      X_test = stdsc.transform(X_test_raw)\n",
        "    \n",
        "      # Train the model\n",
        "      model_train2 = model_dict2[model].fit(X_train,y_train)\n",
        "\n",
        "      # Calculate the confusion matrix\n",
        "      cm = confusion_matrix(y_test, model_train2.predict(X_test))\n",
        "      cm = cm.T\n",
        "      # Add the score to the previous confusion matrix of previous model\n",
        "      array = array + cm\n",
        "\n",
        "      # Nornalised cfmat\n",
        "      Nor_cfmat = array/ array.astype(np.float).sum(axis=0)\n",
        "      df = pd.DataFrame(Nor_cfmat, index = ['Predicted Not Default', 'Predicted Default'], columns = ['Actual Not Default', 'Actual Default'])\n",
        "        \n",
        "    print(model,'\\tBalanced data' if i == 1  else '\\tImbalanced data')\n",
        "    print(df)\n",
        "    print(\"\\n\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "osxCi7Wr-vdv",
        "outputId": "f6404001-4bb1-465d-c73e-75e67304c4bd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 319
        }
      },
      "source": [
        "reduce(reduced_data,1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "LogisticReg \tBalanced data\n",
            "                       Actual Not Default  Actual Default\n",
            "Predicted Not Default            0.640714        0.372479\n",
            "Predicted Default                0.359286        0.627521\n",
            "\n",
            "\n",
            "Random Forest \tBalanced data\n",
            "                       Actual Not Default  Actual Default\n",
            "Predicted Not Default            0.616096        0.385737\n",
            "Predicted Default                0.383904        0.614263\n",
            "\n",
            "\n",
            "KNN \tBalanced data\n",
            "                       Actual Not Default  Actual Default\n",
            "Predicted Not Default             0.62584        0.378168\n",
            "Predicted Default                 0.37416        0.621832\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "4Q64LlgwaAEk"
      },
      "source": [
        "#Q4\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "NFLvTcE5aDCX"
      },
      "source": [
        "Choosing the right model depends on the context in which it is used. Can you think of examples where one would worry more about false positives than false negatives, and vice versa?\n",
        "Another way to compare models is to compute the ROC (receiver-operating characteristic) curve that varies the classi cation threshold and shows the true positive rate (share of defaulters correctly classi ed)\n",
        "against the false positive rate (share of non-defaulters incorrectly classi ed). Plot the ROC curves and compute the area-under-the-curve (AUC) for a LDA and 50-NN model and explain which model should\n",
        "be preferred in your opinion. Hint: Do that without 10-fold cross-validation.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "cfndIjDeKGHR",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import roc_curve, roc_auc_score\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.datasets import make_classification\n",
        "import sklearn.metrics as metrics"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Ehv1gKaMemtq",
        "colab": {}
      },
      "source": [
        "# Classifier\n",
        "model_dict3 = {\n",
        "    'LDA':LinearDiscriminantAnalysis()\n",
        "    ,'KNN':KNeighborsClassifier(n_neighbors=50)\n",
        "}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "EXR73WJZleKz",
        "colab": {}
      },
      "source": [
        "trainX, testX, trainy, testy = train_test_split(X, y, test_size=0.2, random_state=0)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "KLHCj6L0spTp",
        "outputId": "f899b42b-c1bf-4412-a849-fe3021c2c4db",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 606
        }
      },
      "source": [
        "for model in model_dict3:\n",
        "  # calculate the fpr and tpr for all thresholds of the classification\n",
        "  pipe_lr = Pipeline([('sc',StandardScaler()),\n",
        "           ('clf',model_dict3[model])\n",
        "           ])\n",
        "  \n",
        "  probs = pipe_lr.fit(trainX,trainy).predict_proba(testX)\n",
        "  preds = probs[:,1]\n",
        "  fpr, tpr, threshold = metrics.roc_curve(testy, preds, pos_label=\"1\")\n",
        "  roc_auc = metrics.auc(fpr, tpr)\n",
        "  print('AUC: %.5f' % roc_auc)\n",
        "  # method I: plt\n",
        "\n",
        "  plt.title('Receiver Operating Characteristic')\n",
        "  plt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % roc_auc)\n",
        "  plt.legend(loc = 'lower right')\n",
        "  plt.plot([0, 1], [0, 1],'r--')\n",
        "  plt.xlim([0, 1])\n",
        "  plt.ylim([0, 1])\n",
        "  plt.ylabel('True Positive Rate')\n",
        "  plt.xlabel('False Positive Rate')\n",
        "  plt.show()\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "AUC: 0.69128\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYoAAAEWCAYAAAB42tAoAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "AUC: 0.67236\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYoAAAEWCAYAAAB42tAoAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "UfssxKLOaekn"
      },
      "source": [
        "# Q5\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "SziLvv_bbzKL"
      },
      "source": [
        "5.(10 points) Please explain in your own words how you might use the Lasso estimation method to\n",
        "select a subset of attributes. In particular, please explain what the Lasso parameter is for, and how\n",
        "increases in change the estimates you obtain from the Lasso.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "q6US2cHCb2xs"
      },
      "source": [
        "Lasso parameter Î» regularizes the coefficients such that if the coefficients take large values the optimization function is penalized. When Î» = 0, the coefficients as simple linear regression. When 0 < Î» < âˆž, the coefficients between 0 and that of simple linear regression. When Î» = âˆž, All coefficients zero. Therefore, the minimization objective equals LS Objects + Î» * (sum of the absolute value of coefficients)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "kWTondYXcAJF"
      },
      "source": [
        "\n",
        "#Q6"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "UnRF0eIpb3fm"
      },
      "source": [
        "6. (5 points) First, let's use the Lasso approach, and compare it to previous methods. Apply the\n",
        "Logistic Regression model with Lasso penalization method to the to the default response variable (1 or\n",
        "0), and the entire set of attributes. For now, set to 0.1. Compute the resulting confusion matrix using\n",
        "10-fold cross-validation (fill in the table).\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "gBh2eYczWkAG",
        "colab": {}
      },
      "source": [
        "from sklearn.linear_model import LogisticRegressionCV, LogisticRegression\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn import linear_model\n",
        "from sklearn.datasets import load_breast_cancer"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "U4lixt1d2A4c",
        "colab": {}
      },
      "source": [
        "logistic_lasso= LogisticRegressionCV(Cs = 10, cv=10, penalty = 'l1', solver = 'liblinear', )\n",
        "Model6 = logistic_lasso.fit(X,y)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C-jXuvFBK268",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_predicted =  Model6.predict(X)\n",
        "c = confusion_matrix(y, y_predicted)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tSm8saT_K5Su",
        "colab_type": "code",
        "outputId": "99802192-3129-433e-f8af-95d59c150919",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        }
      },
      "source": [
        "Nor_cfmat = c/ c.astype(np.float).sum(axis=0)\n",
        "df_q6 = pd.DataFrame(Nor_cfmat, index = ['Predicted Not Default', 'Predicted Default'], columns = ['Actual Not Default', 'Actual Default'])\n",
        "print(df_q6)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "                       Actual Not Default  Actual Default\n",
            "Predicted Not Default            0.754048        0.458965\n",
            "Predicted Default                0.245952        0.541035\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "UmJn1lwBcDgl"
      },
      "source": [
        "#Q7"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Rk2Mq5m5b8uQ"
      },
      "source": [
        "# 7. (10 points) \n",
        "Next, apply the Logistic Regression model with Lasso penalization method to the default\n",
        "response variable (1 or 0), and the entire set of attributes on the entire dataset (not inside 10-fold\n",
        "cross-validation) and once again, constrain the model to have at most 10 attributes in it (aim for 8 to\n",
        "10). Let's call the resulting set of attributes the LASSO-MODEL. What is the value of now? Which\n",
        "attributes are those? Did your intuition about the correct set of attributes in the REDUCED-MODEL\n",
        "match the algorithmic results that you obtained from the LASSO-MODEL? Discuss.\n",
        "Hint: Start with di erent values for , e.g. 1e-15, 1e-10, 1e-8, 1e-5,1e-4, 1e-3,1e-2, 1, 5, 10, check\n",
        "the number of coe cients that are zero, and iterate the value of until you get the desired number of\n",
        "coe cients that are shrunk to zero.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "M_YItXz8xCye",
        "outputId": "688315fd-da87-474d-8c15-059091959d98",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 185
        }
      },
      "source": [
        "alpha = [1e-15, 1e-10, 1e-8, 1e-5,1e-4, 1e-3,1e-2, 1, 5, 10]\n",
        "coefficients = []\n",
        "for c in  alpha:\n",
        "    LASSO = LogisticRegression(penalty='l1', C=c, solver='liblinear')\n",
        "    LASSO_MODEL = LASSO.fit(X,y)\n",
        "    print('alpha:',c )\n",
        "    coefficients.append(LASSO_MODEL.coef_)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "alpha: 1e-15\n",
            "alpha: 1e-10\n",
            "alpha: 1e-08\n",
            "alpha: 1e-05\n",
            "alpha: 0.0001\n",
            "alpha: 0.001\n",
            "alpha: 0.01\n",
            "alpha: 1\n",
            "alpha: 5\n",
            "alpha: 10\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9pOCfbD5_07v",
        "colab_type": "code",
        "outputId": "4edf0e6d-d96b-485d-f3ab-4bb01b2282c6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 185
        }
      },
      "source": [
        "for i in range(10):\n",
        "    print('C:', alpha[i],'|','Number of non-zero coefficients:',np.count_nonzero(coefficients[i]))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "C: 1e-15 | Number of non-zero coefficients: 0\n",
            "C: 1e-10 | Number of non-zero coefficients: 0\n",
            "C: 1e-08 | Number of non-zero coefficients: 2\n",
            "C: 1e-05 | Number of non-zero coefficients: 12\n",
            "C: 0.0001 | Number of non-zero coefficients: 15\n",
            "C: 0.001 | Number of non-zero coefficients: 20\n",
            "C: 0.01 | Number of non-zero coefficients: 29\n",
            "C: 1 | Number of non-zero coefficients: 35\n",
            "C: 5 | Number of non-zero coefficients: 35\n",
            "C: 10 | Number of non-zero coefficients: 35\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dI46d_up_18S",
        "colab_type": "code",
        "outputId": "6f3f26b7-4519-481e-a0a5-5efcee09e243",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 185
        }
      },
      "source": [
        "alpha1 = [0.001, 0.002,0.003,0.004,0.005, 0.006,0.007,0.008,0.009,0.01]\n",
        "coefficients1 = []\n",
        "for d in  alpha1:\n",
        "    LASSO1 = LogisticRegression(penalty='l1', C=d, solver='liblinear')\n",
        "    LASSO_MODEL1 = LASSO1.fit(X,y)\n",
        "    print('alpha1:',d )\n",
        "    coefficients1.append(LASSO_MODEL1.coef_)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "alpha1: 0.001\n",
            "alpha1: 0.002\n",
            "alpha1: 0.003\n",
            "alpha1: 0.004\n",
            "alpha1: 0.005\n",
            "alpha1: 0.006\n",
            "alpha1: 0.007\n",
            "alpha1: 0.008\n",
            "alpha1: 0.009\n",
            "alpha1: 0.01\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "htGzqNY0_2-h",
        "colab_type": "code",
        "outputId": "b85051b0-cc00-4208-a2a5-2cc30189edde",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 185
        }
      },
      "source": [
        "for i in range(10):\n",
        "    print('C:', alpha1[i],'|','Number of non-zero coefficients:',np.count_nonzero(coefficients1[i]))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "C: 0.001 | Number of non-zero coefficients: 20\n",
            "C: 0.002 | Number of non-zero coefficients: 24\n",
            "C: 0.003 | Number of non-zero coefficients: 24\n",
            "C: 0.004 | Number of non-zero coefficients: 26\n",
            "C: 0.005 | Number of non-zero coefficients: 27\n",
            "C: 0.006 | Number of non-zero coefficients: 27\n",
            "C: 0.007 | Number of non-zero coefficients: 28\n",
            "C: 0.008 | Number of non-zero coefficients: 29\n",
            "C: 0.009 | Number of non-zero coefficients: 29\n",
            "C: 0.01 | Number of non-zero coefficients: 29\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Akv5u_Mf_3da",
        "colab_type": "code",
        "outputId": "87f42505-c965-4272-e386-1aea9a283400",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "lamda = 1/0.009\n",
        "print(lamda)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "111.11111111111111\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "6AuMSuBscH5c"
      },
      "source": [
        "#Q8"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "O3yAwcWXcPfK"
      },
      "source": [
        "*8*.Congratulations! You have now estimated a set of different models for default forecasting. Now assume that you are running a bank. Please pick one set of attributes and one algorithm to implement in the bank. Do you now have sufficient information to run a loan business? What else might\n",
        "you need to consider?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "qYIY-DtJcRcR"
      },
      "source": [
        "Assume we are running a bank, we are going to create a model for assessing loan risk, identify the safest default risk under different features. \n",
        "The first step is feature selection which involved identifying which of the provided characteristics were most indicative. We plan to use  Lasso regression to reduce over-fitting and select a set of ten attributes. \n",
        "The next step is creating a model that required taking those features and using the Logistic model to determine the probability of default by given the features we are selected.\n",
        "\n",
        "However, under this assumption, we still do not have sufficient information to run a loan business. On the one hand, the dataset of attributes we are picked probably contains too much missing data. Although the attributes could get a higher coefficient value, we still need to use their mean instead.  Under this preprocess, it could introduce some bias. On the other hand, there is not a universal algorithm that could perfectly fit every dataset. If we only use one algorithm on implementation, it may cause the execution strategy for this approach to be not comparable.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "uOKDeZExcUJl"
      },
      "source": [
        "#Q9"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "XMsR388PcVc8"
      },
      "source": [
        "9. (5 points) How do the results using the full set of attributes (FULL-MODEL) compare to those that\n",
        "you personally selected (REDUCED-MODEL) in order to predict if a loan will default? What do you\n",
        "think is more important in this particular example, the set of attributes, or the classi cation technique?\n",
        "Discuss.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "YvzLrkyHcX2O"
      },
      "source": [
        "The result of the full set of attributes implies around 30% of people will be a default, but the reduced model shows this number should be lower.  In this case, when we manipulate some features incorrectly, it will overfitting or underfitting our analysis. For example, some attributes leak information after the loan has already been funded, some does not alter the borrower's ability to pay back the loan. However, for each classification technique, the results are quite close. Therefore, it is more important to use a different set of attributes. \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "B0xUBcR_ceU3"
      },
      "source": [
        "#Q10\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "O8QQzoj0cfwa"
      },
      "source": [
        "10. (5 points) Are these the best models you could possibly create? Name one other possible classi\n",
        "cation technique and any additional attributes that you might be able to add in order to improve the\n",
        "confusion matrix. Please justify your choices.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "C9lWR_Lycg3w"
      },
      "source": [
        "We want to use Recursive Feature Elimination (RFE) as another way to choose attributes. RFE is repeatedly constructing a model and choose either the best or worst performing feature, then repeating the process with the rest of the features. This process is applied until all features in the dataset are exhausted. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Hlnt6nvNqFtZ",
        "colab": {}
      },
      "source": [
        "y=df_loan[\"loan_status\"]\n",
        "X=df_loan.iloc[:,df_loan.columns!=\"loan_status\"]\n",
        "from imblearn.over_sampling import SMOTE  \n",
        "\n",
        "X_train_raw, y_train = RandomUnderSampler(random_state=0).fit_sample(X_train_raw,y_train)\n",
        "os = SMOTE(random_state=0)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)\n",
        "columns = X_train.columns\n",
        "os_data_X,os_data_y=os.fit_sample(X_train, y_train)\n",
        "os_data_X = pd.DataFrame(data=os_data_X,columns=columns )\n",
        "os_data_y= pd.DataFrame(data=os_data_y,columns=['target'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "NzkijZIgHmyp",
        "outputId": "ab6241ab-0b52-48a8-efdd-70d0d2c4ff53",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 101
        }
      },
      "source": [
        "df_loan_vars=df_loan.columns.values.tolist()\n",
        "from sklearn.feature_selection import RFE\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "logreg = LogisticRegression()\n",
        "rfe = RFE(logreg, 10)\n",
        "rfe = rfe.fit(os_data_X, os_data_y.values.ravel())\n",
        "print(rfe.support_)\n",
        "print(rfe.ranking_)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[False  True  True  True False False False  True  True False  True False\n",
            " False False False False False False False  True False  True  True False\n",
            " False False False False  True False False False False False False]\n",
            "[ 5  1  1  1  4 11 19  1  1 16  1 15  6 20  7  2 14 21 13  1 17  1  1 23\n",
            "  3 25 24 12  1 26  9 10 18 22  8]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "9gNaLNWJ20u1"
      },
      "source": [
        "The RFE has helped us select the following features: 'term','int_rate','sub_grade','dti','fico_range_high','purpose','num_actv_bc_tl','num_il_tl','num_op_rev_tl','revol_bal'"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "VE-OlUwG39rE",
        "outputId": "b7eed1dc-f935-4a4e-fc11-b3cda8563779",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "cols = ['term','int_rate','sub_grade','dti','fico_range_high','purpose','num_actv_bc_tl','num_il_tl','num_op_rev_tl','revol_bal']\n",
        "X=os_data_X[cols]\n",
        "y=['target']\n",
        "\n",
        "logreg = LogisticRegression()\n",
        "logreg.fit(X_train, y_train)\n",
        "\n",
        "y_pred = logreg.predict(X_test)\n",
        "print('Accuracy of logistic regression classifier on test set: {:.2f}'.format(logreg.score(X_test, y_test)))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of logistic regression classifier on test set: 0.73\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "tL15clW754Ps",
        "outputId": "8475f99c-3298-46fe-d4ab-67b399ac2586",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        }
      },
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "confusion_matrix = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "Nor_cfmat = confusion_matrix/ confusion_matrix.astype(np.float).sum(axis=0)\n",
        "df_q10 = pd.DataFrame(Nor_cfmat, index = ['Predicted Not Default', 'Predicted Default'], columns = ['Actual Not Default', 'Actual Default'])\n",
        "print(df_q10)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "                       Actual Not Default  Actual Default\n",
            "Predicted Not Default            0.731048        0.518519\n",
            "Predicted Default                0.268952        0.481481\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "DRiEHufJ6FC6",
        "outputId": "02104e96-df75-49db-ccc4-6692e80a8e44",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 168
        }
      },
      "source": [
        "from sklearn.metrics import classification_report\n",
        "print(classification_report(y_test, y_pred))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.73      1.00      0.84     16185\n",
            "           1       0.48      0.01      0.01      5978\n",
            "\n",
            "    accuracy                           0.73     22163\n",
            "   macro avg       0.61      0.50      0.43     22163\n",
            "weighted avg       0.66      0.73      0.62     22163\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "y4y5Rlw1ckRu"
      },
      "source": [
        "\n",
        "#Q11\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Uf0OHgrYcoQ8"
      },
      "source": [
        "11. (10 points) Lastly, we will do a proper out-of-sample test of your models, which is the challenge\n",
        "you would encounter in the real world. For that purpose, t or train your Logistic, LDA and 50-NN\n",
        "models on the data from Part I (with undersampling), and test them on the datasets (a) and (b) for\n",
        "Part II (no undersampling - why?). Report the AUC for the three models below. Within each dataset,\n",
        "compare the relative performance of the three models with your previous results and discuss. Do you\n",
        "nd overall di erences in performance across datasets? Discuss.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "BhWJOb75cpLz",
        "colab": {}
      },
      "source": [
        "df2=pd.read_csv('/Users/wuyating/Desktop/Assignment/Loan_data_part_II_a.csv')\n",
        "df2[\"home_ownership\"]=df2[\"home_ownership\"].astype(\"category\")\n",
        "df2[\"purpose\"]=df2[\"purpose\"].astype(\"category\")\n",
        "df2[\"sub_grade\"]=df2[\"sub_grade\"].astype(\"category\")\n",
        "df2[\"verification_status\"]=df2[\"verification_status\"].astype(\"category\")\n",
        "df2[\"loan_status\"]=np.where(df2[\"loan_status\"] == 'Fail',\"1\",\"0\")\n",
        "df2[\"loan_status\"]=df2[\"loan_status\"].astype(\"category\")\n",
        "df2.dtypes"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fciLBL_r-ULg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "trainX=features\n",
        "trainy=y\n",
        "testX=df2.iloc[:,df2.columns!=\"loan_status\"]\n",
        "testy=df2[\"loan_status\"]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E30KOTPb-ULi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "model_dict4 = {\n",
        "    'LDA':LinearDiscriminantAnalysis()\n",
        "    ,'KNN':KNeighborsClassifier(n_neighbors=50)\n",
        "    ,'LogReg':LogisticRegression()\n",
        "}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WWVQ3FSn-ULk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for model in model_dict4:\n",
        "  # calculate the fpr and tpr for all thresholds of the classification\n",
        "  pipe_lr = Pipeline([('sc',StandardScaler()),\n",
        "           ('clf',model_dict4[model])\n",
        "           ])\n",
        "  \n",
        "  probs = pipe_lr.fit(trainX,trainy).predict_proba(testX)\n",
        "  preds = probs[:,1]\n",
        "  fpr, tpr, threshold = metrics.roc_curve(testy, preds, pos_label=\"1\")\n",
        "  roc_auc = metrics.auc(fpr, tpr)\n",
        "  print('AUC: %.5f' % roc_auc)\n",
        "  # method I: plt\n",
        "\n",
        "  plt.title('Receiver Operating Characteristic')\n",
        "  plt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % roc_auc)\n",
        "  plt.legend(loc = 'lower right')\n",
        "  plt.plot([0, 1], [0, 1],'r--')\n",
        "  plt.xlim([0, 1])\n",
        "  plt.ylim([0, 1])\n",
        "  plt.ylabel('True Positive Rate')\n",
        "  plt.xlabel('False Positive Rate')\n",
        "  plt.show()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IxJp7NGg-ULm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df3=pd.read_csv('/Users/wuyating/Desktop/Assignment/Loan_data_part_II_b.csv')\n",
        "df3[\"home_ownership\"]=df3[\"home_ownership\"].astype(\"category\")\n",
        "df3[\"purpose\"]=df3[\"purpose\"].astype(\"category\")\n",
        "df3[\"sub_grade\"]=df3[\"sub_grade\"].astype(\"category\")\n",
        "df3[\"verification_status\"]=df3[\"verification_status\"].astype(\"category\")\n",
        "df3[\"loan_status\"]=np.where(df3[\"loan_status\"] == 'Fail',\"1\",\"0\")\n",
        "df3[\"loan_status\"]=df3[\"loan_status\"].astype(\"category\")\n",
        "df3.dtypes"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jEeQcmjp-ULo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "trainX=features\n",
        "trainy=y\n",
        "testX=df3.iloc[:,df2.columns!=\"loan_status\"]\n",
        "testy=df3[\"loan_status\"]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pPXRkPB7-ULr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for model in model_dict4:\n",
        "  # calculate the fpr and tpr for all thresholds of the classification\n",
        "  pipe_lr = Pipeline([('sc',StandardScaler()),\n",
        "           ('clf',model_dict4[model])\n",
        "           ])\n",
        "  \n",
        "  probs = pipe_lr.fit(trainX,trainy).predict_proba(testX)\n",
        "  preds = probs[:,1]\n",
        "  fpr, tpr, threshold = metrics.roc_curve(testy, preds, pos_label=\"1\")\n",
        "  roc_auc = metrics.auc(fpr, tpr)\n",
        "  print('AUC: %.5f' % roc_auc)\n",
        "  # method I: plt\n",
        "\n",
        "  plt.title('Receiver Operating Characteristic')\n",
        "  plt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % roc_auc)\n",
        "  plt.legend(loc = 'lower right')\n",
        "  plt.plot([0, 1], [0, 1],'r--')\n",
        "  plt.xlim([0, 1])\n",
        "  plt.ylim([0, 1])\n",
        "  plt.ylabel('True Positive Rate')\n",
        "  plt.xlabel('False Positive Rate')\n",
        "  plt.show()\n"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}